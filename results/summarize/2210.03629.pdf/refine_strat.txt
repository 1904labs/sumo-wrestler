This paper explores the use of large language models (LLMs) to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two. The approach, named ReAct, is applied to a diverse set of language and decision making tasks, including question answering (HotPotQA, Yang et al., 2018), fact veriÔ¨Åcation (Fever, Thorne et al., 2018), text-based game (ALFWorld, Shridhar et al., 2020b), webpage navigation (WebShop, Yao et al., 2022), Faithful Reasoning (Creswell and Shanahan, 2022), Selection-Inference (Creswell et al., 2022), ELI5 (Fan et al., 2019), Vygotsky, Luria, and the Social Brain (Fernyhough, 2010), Improving Alignment of Dialogue Agents (Glaese et al., 2022), A Simple Language Model for Task-Oriented Dialogue (Hosseini-Asl et al., 2020), Language Models as Zero-Shot Planners (Huang et al., 2022a), Inner Monologue (Huang et al., 2022b), LILA (Madaan and
Time to summarize using chain_type = map_reduce: 1322.6233961582184